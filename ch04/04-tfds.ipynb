{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3105de88",
      "metadata": {
        "id": "3105de88"
      },
      "source": [
        "# 4장. 텐서플로 데이터셋으로 공개 데이터 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0e8541",
      "metadata": {
        "id": "fc0e8541"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/aiml4coders/blob/main/ch04/04-tfds.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"61\" />주피터 노트북 뷰어로 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/aiml4coders/blob/main/ch04/04-tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba5f7ba",
      "metadata": {
        "id": "bba5f7ba"
      },
      "source": [
        "## TFDS 시작하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bee79a3",
      "metadata": {
        "scrolled": true,
        "id": "6bee79a3",
        "outputId": "40ad9731-5679-4b50-954a-def901e91ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n",
            "train\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "mnist_data = tfds.load(\"fashion_mnist\")\n",
        "for item in mnist_data:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a439642d",
      "metadata": {
        "id": "a439642d",
        "outputId": "e5b1673b-0af4-4f25-fab2-3744dc22b485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
          ]
        }
      ],
      "source": [
        "mnist_train = tfds.load(name=\"fashion_mnist\", split=\"train\")\n",
        "assert isinstance(mnist_train, tf.data.Dataset)\n",
        "print(type(mnist_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3d04694b",
      "metadata": {
        "scrolled": true,
        "id": "3d04694b",
        "outputId": "3248e78a-00dc-4a99-e990-a440a242ae04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label'])\n"
          ]
        }
      ],
      "source": [
        "for item in mnist_train.take(1):\n",
        "    print(type(item))\n",
        "    print(item.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1594fc0a",
      "metadata": {
        "id": "1594fc0a",
        "outputId": "31a637c3-6063-4350-dfca-f476cd83361e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label'])\n",
            "tf.Tensor(\n",
            "[[[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 77]\n",
            "  [227]\n",
            "  [227]\n",
            "  [208]\n",
            "  [210]\n",
            "  [225]\n",
            "  [216]\n",
            "  [ 85]\n",
            "  [ 32]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 61]\n",
            "  [100]\n",
            "  [ 97]\n",
            "  [ 80]\n",
            "  [ 57]\n",
            "  [117]\n",
            "  [227]\n",
            "  [238]\n",
            "  [115]\n",
            "  [ 49]\n",
            "  [ 78]\n",
            "  [106]\n",
            "  [108]\n",
            "  [ 71]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 81]\n",
            "  [105]\n",
            "  [ 80]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 64]\n",
            "  [ 44]\n",
            "  [ 21]\n",
            "  [ 13]\n",
            "  [ 44]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 80]\n",
            "  [114]\n",
            "  [ 80]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 26]\n",
            "  [ 92]\n",
            "  [ 69]\n",
            "  [ 68]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 71]\n",
            "  [ 74]\n",
            "  [ 83]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 83]\n",
            "  [ 77]\n",
            "  [108]\n",
            "  [ 34]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 69]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 71]\n",
            "  [ 71]\n",
            "  [ 77]\n",
            "  [ 69]\n",
            "  [ 66]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 94]\n",
            "  [ 63]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 63]\n",
            "  [ 95]\n",
            "  [ 66]\n",
            "  [ 68]\n",
            "  [ 72]\n",
            "  [ 72]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 77]\n",
            "  [106]\n",
            "  [ 61]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 80]\n",
            "  [108]\n",
            "  [ 71]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 71]\n",
            "  [ 69]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 78]\n",
            "  [ 72]\n",
            "  [ 85]\n",
            "  [128]\n",
            "  [ 64]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 88]\n",
            "  [120]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 83]\n",
            "  [ 83]\n",
            "  [ 66]\n",
            "  [111]\n",
            "  [123]\n",
            "  [ 78]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 85]\n",
            "  [134]\n",
            "  [ 74]\n",
            "  [ 85]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 81]\n",
            "  [ 75]\n",
            "  [ 61]\n",
            "  [151]\n",
            "  [115]\n",
            "  [ 91]\n",
            "  [ 12]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 10]\n",
            "  [ 85]\n",
            "  [153]\n",
            "  [ 83]\n",
            "  [ 80]\n",
            "  [ 68]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 68]\n",
            "  [ 61]\n",
            "  [162]\n",
            "  [122]\n",
            "  [ 78]\n",
            "  [  6]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 30]\n",
            "  [ 75]\n",
            "  [154]\n",
            "  [ 85]\n",
            "  [ 80]\n",
            "  [ 71]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 49]\n",
            "  [191]\n",
            "  [132]\n",
            "  [ 72]\n",
            "  [ 15]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 58]\n",
            "  [ 66]\n",
            "  [174]\n",
            "  [115]\n",
            "  [ 66]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 78]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 66]\n",
            "  [ 49]\n",
            "  [222]\n",
            "  [131]\n",
            "  [ 77]\n",
            "  [ 37]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 69]\n",
            "  [ 55]\n",
            "  [179]\n",
            "  [139]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 80]\n",
            "  [ 64]\n",
            "  [ 55]\n",
            "  [242]\n",
            "  [111]\n",
            "  [ 95]\n",
            "  [ 44]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 74]\n",
            "  [ 57]\n",
            "  [159]\n",
            "  [180]\n",
            "  [ 55]\n",
            "  [ 92]\n",
            "  [ 64]\n",
            "  [ 72]\n",
            "  [ 74]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 78]\n",
            "  [ 55]\n",
            "  [ 66]\n",
            "  [255]\n",
            "  [ 97]\n",
            "  [108]\n",
            "  [ 49]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 74]\n",
            "  [ 66]\n",
            "  [145]\n",
            "  [153]\n",
            "  [ 72]\n",
            "  [ 83]\n",
            "  [ 58]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 80]\n",
            "  [ 30]\n",
            "  [132]\n",
            "  [255]\n",
            "  [ 37]\n",
            "  [122]\n",
            "  [ 60]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 80]\n",
            "  [ 69]\n",
            "  [142]\n",
            "  [180]\n",
            "  [142]\n",
            "  [ 57]\n",
            "  [ 64]\n",
            "  [ 78]\n",
            "  [ 74]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 85]\n",
            "  [ 21]\n",
            "  [185]\n",
            "  [227]\n",
            "  [ 37]\n",
            "  [143]\n",
            "  [ 63]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 83]\n",
            "  [ 71]\n",
            "  [136]\n",
            "  [194]\n",
            "  [126]\n",
            "  [ 46]\n",
            "  [ 69]\n",
            "  [ 75]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 78]\n",
            "  [ 38]\n",
            "  [139]\n",
            "  [185]\n",
            "  [ 60]\n",
            "  [151]\n",
            "  [ 58]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  4]\n",
            "  [ 81]\n",
            "  [ 74]\n",
            "  [145]\n",
            "  [177]\n",
            "  [ 78]\n",
            "  [ 49]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 72]\n",
            "  [ 63]\n",
            "  [ 80]\n",
            "  [156]\n",
            "  [117]\n",
            "  [153]\n",
            "  [ 55]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 10]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [157]\n",
            "  [163]\n",
            "  [ 61]\n",
            "  [ 55]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 71]\n",
            "  [ 60]\n",
            "  [ 98]\n",
            "  [156]\n",
            "  [132]\n",
            "  [ 58]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 13]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [157]\n",
            "  [143]\n",
            "  [ 43]\n",
            "  [ 61]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 71]\n",
            "  [ 58]\n",
            "  [ 80]\n",
            "  [157]\n",
            "  [120]\n",
            "  [ 66]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 81]\n",
            "  [ 74]\n",
            "  [156]\n",
            "  [114]\n",
            "  [ 35]\n",
            "  [ 72]\n",
            "  [ 71]\n",
            "  [ 75]\n",
            "  [ 78]\n",
            "  [ 72]\n",
            "  [ 66]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 64]\n",
            "  [ 63]\n",
            "  [165]\n",
            "  [119]\n",
            "  [ 68]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 23]\n",
            "  [ 85]\n",
            "  [ 81]\n",
            "  [177]\n",
            "  [ 57]\n",
            "  [ 52]\n",
            "  [ 77]\n",
            "  [ 71]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 72]\n",
            "  [ 75]\n",
            "  [ 74]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 75]\n",
            "  [ 64]\n",
            "  [ 37]\n",
            "  [173]\n",
            "  [ 95]\n",
            "  [ 72]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 26]\n",
            "  [ 81]\n",
            "  [ 86]\n",
            "  [160]\n",
            "  [ 20]\n",
            "  [ 75]\n",
            "  [ 77]\n",
            "  [ 77]\n",
            "  [ 80]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 89]\n",
            "  [ 78]\n",
            "  [ 81]\n",
            "  [ 83]\n",
            "  [ 80]\n",
            "  [ 74]\n",
            "  [ 20]\n",
            "  [177]\n",
            "  [ 77]\n",
            "  [ 74]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 49]\n",
            "  [ 77]\n",
            "  [ 91]\n",
            "  [200]\n",
            "  [  0]\n",
            "  [ 83]\n",
            "  [ 95]\n",
            "  [ 86]\n",
            "  [ 88]\n",
            "  [ 88]\n",
            "  [ 89]\n",
            "  [ 88]\n",
            "  [ 89]\n",
            "  [ 88]\n",
            "  [ 83]\n",
            "  [ 89]\n",
            "  [ 86]\n",
            "  [  0]\n",
            "  [191]\n",
            "  [ 78]\n",
            "  [ 80]\n",
            "  [ 24]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 54]\n",
            "  [ 71]\n",
            "  [108]\n",
            "  [165]\n",
            "  [  0]\n",
            "  [ 24]\n",
            "  [ 57]\n",
            "  [ 52]\n",
            "  [ 57]\n",
            "  [ 60]\n",
            "  [ 60]\n",
            "  [ 60]\n",
            "  [ 63]\n",
            "  [ 63]\n",
            "  [ 77]\n",
            "  [ 89]\n",
            "  [ 52]\n",
            "  [  0]\n",
            "  [211]\n",
            "  [ 97]\n",
            "  [ 77]\n",
            "  [ 61]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 68]\n",
            "  [ 91]\n",
            "  [117]\n",
            "  [137]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [216]\n",
            "  [ 94]\n",
            "  [ 97]\n",
            "  [ 57]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 54]\n",
            "  [115]\n",
            "  [105]\n",
            "  [185]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  1]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [153]\n",
            "  [ 78]\n",
            "  [106]\n",
            "  [ 37]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]\n",
            "\n",
            " [[  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [ 18]\n",
            "  [ 61]\n",
            "  [ 41]\n",
            "  [103]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [106]\n",
            "  [ 47]\n",
            "  [ 69]\n",
            "  [ 23]\n",
            "  [  0]\n",
            "  [  0]\n",
            "  [  0]]], shape=(28, 28, 1), dtype=uint8)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for item in mnist_train.take(1):\n",
        "    print(type(item))\n",
        "    print(item.keys())\n",
        "    print(item['image'])\n",
        "    print(item['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aeac7308",
      "metadata": {
        "id": "aeac7308",
        "outputId": "45787f77-d98d-4595-f81f-2caab489f59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='fashion_mnist',\n",
            "    version=3.0.1,\n",
            "    description='Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.',\n",
            "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
            "      author    = {Han Xiao and\n",
            "                   Kashif Rasul and\n",
            "                   Roland Vollgraf},\n",
            "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
            "                   Algorithms},\n",
            "      journal   = {CoRR},\n",
            "      volume    = {abs/1708.07747},\n",
            "      year      = {2017},\n",
            "      url       = {http://arxiv.org/abs/1708.07747},\n",
            "      archivePrefix = {arXiv},\n",
            "      eprint    = {1708.07747},\n",
            "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
            "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
            "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mnist_test, info = tfds.load(name=\"fashion_mnist\", with_info=\"true\")\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9013edc",
      "metadata": {
        "id": "e9013edc"
      },
      "source": [
        "## 케라스 모델에서 TFDS 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "202cc8b2",
      "metadata": {
        "id": "202cc8b2"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "31c4b935",
      "metadata": {
        "id": "31c4b935",
        "outputId": "0d9e87f8-e3f6-492e-d044-cd8b667ef58c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        }
      ],
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    tfds.as_numpy(tfds.load('fashion_mnist',\n",
        "                            split = ['train', 'test'], \n",
        "                            batch_size=-1, \n",
        "                            as_supervised=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "16d90467",
      "metadata": {
        "scrolled": true,
        "id": "16d90467",
        "outputId": "fe8edb30-59d3-4784-b282-9e5349db1aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.5286 - accuracy: 0.8135\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3999 - accuracy: 0.8550\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3682 - accuracy: 0.8663\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3464 - accuracy: 0.8730\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3302 - accuracy: 0.8784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f461c123550>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = \\\n",
        "    tfds.load('fashion_mnist', \n",
        "              split = ['train', 'test'],\n",
        "              batch_size=-1, \n",
        "              as_supervised=True)\n",
        "\n",
        "training_images = tf.cast(training_images, tf.float32) / 255.0\n",
        "test_images = tf.cast(test_images, tf.float32) / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8731883e",
      "metadata": {
        "id": "8731883e",
        "outputId": "37e2c3d5-109e-4a7d-9088-6047ebe0d363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 15s 50ms/step - loss: 2.0467 - accuracy: 0.8452\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0874 - accuracy: 0.9708\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.1068 - accuracy: 0.9766\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0922 - accuracy: 0.9688\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 5s 47ms/step - loss: 0.0583 - accuracy: 0.9776\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.2314 - accuracy: 0.9464\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 5s 46ms/step - loss: 0.0079 - accuracy: 0.9971\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0253 - accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0441 - accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0423 - accuracy: 0.9825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4606db4390>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data = tfds.load('horses_or_humans', split='train', as_supervised=True) \n",
        "\n",
        "train_batches = data.shuffle(100).batch(10)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
        "                           input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_batches, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "11dd9128",
      "metadata": {
        "id": "11dd9128"
      },
      "outputs": [],
      "source": [
        "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3df701a2",
      "metadata": {
        "id": "3df701a2"
      },
      "outputs": [],
      "source": [
        "validation_batches = val_data.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1f5abb62",
      "metadata": {
        "id": "1f5abb62",
        "outputId": "a44585c9-b0b2-419d-df8e-e768238faba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 6s 55ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 4.3995 - val_accuracy: 0.8359\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 6s 53ms/step - loss: 1.1711e-04 - accuracy: 1.0000 - val_loss: 4.5387 - val_accuracy: 0.8359\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 6s 50ms/step - loss: 7.7254e-05 - accuracy: 1.0000 - val_loss: 4.5758 - val_accuracy: 0.8359\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 6s 51ms/step - loss: 5.5316e-05 - accuracy: 1.0000 - val_loss: 4.6251 - val_accuracy: 0.8398\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 6s 52ms/step - loss: 4.3427e-05 - accuracy: 1.0000 - val_loss: 4.6837 - val_accuracy: 0.8398\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 6s 52ms/step - loss: 3.5382e-05 - accuracy: 1.0000 - val_loss: 4.7269 - val_accuracy: 0.8359\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 6s 52ms/step - loss: 3.0126e-05 - accuracy: 1.0000 - val_loss: 4.7605 - val_accuracy: 0.8359\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 6s 51ms/step - loss: 2.5288e-05 - accuracy: 1.0000 - val_loss: 4.7942 - val_accuracy: 0.8359\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 6s 52ms/step - loss: 2.1787e-05 - accuracy: 1.0000 - val_loss: 4.8452 - val_accuracy: 0.8359\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 6s 52ms/step - loss: 1.9278e-05 - accuracy: 1.0000 - val_loss: 4.8804 - val_accuracy: 0.8359\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f461c1391d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(train_batches, epochs=10,\n",
        "          validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead4241e",
      "metadata": {
        "id": "ead4241e"
      },
      "source": [
        "### 특정 버전의 데이터셋 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e825b59",
      "metadata": {
        "id": "8e825b59"
      },
      "outputs": [],
      "source": [
        "data, info = tfds.load(\"horses_or_humans:3.0.0\", with_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dad1df2",
      "metadata": {
        "id": "5dad1df2"
      },
      "source": [
        "## 데이터 증식을 위해 매핑 함수 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0ec01220",
      "metadata": {
        "id": "0ec01220"
      },
      "outputs": [],
      "source": [
        "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
        "train_batches = data.shuffle(100).batch(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1cd15b67",
      "metadata": {
        "id": "1cd15b67"
      },
      "outputs": [],
      "source": [
        "def augmentimages(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image/255)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7908101b",
      "metadata": {
        "id": "7908101b"
      },
      "outputs": [],
      "source": [
        "train = data.map(augmentimages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f9f922f3",
      "metadata": {
        "id": "f9f922f3"
      },
      "outputs": [],
      "source": [
        "train_batches = train.shuffle(100).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05a8f4b",
      "metadata": {
        "id": "e05a8f4b"
      },
      "source": [
        "### 텐서플로 애드온 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a255512e",
      "metadata": {
        "id": "a255512e",
        "outputId": "1704fe28-d5b0-4e02-8aaf-382434befb79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dc21f73b",
      "metadata": {
        "id": "dc21f73b"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "def augmentimages(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image/255)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb1af629",
      "metadata": {
        "id": "fb1af629"
      },
      "source": [
        "## 사용자 정의 분할 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2b49b8-0e6b-4958-aca9-8b6658e547aa",
      "metadata": {
        "id": "7d2b49b8-0e6b-4958-aca9-8b6658e547aa"
      },
      "source": [
        "다운로드 파일을 찾을 수 없다는 에러(404)가 나는 경우 다운로드 경로를 직접 지정하여 사용할 수 있습니다. 예를 들어 다음처럼 cats_vs_dogs 모듈의 `_URL` 변수에 다운로드 경로를 지정합니다. cats_vs_dogs 데이터셋의 최신 다운로드 경로는 https://www.microsoft.com/en-us/download/details.aspx?id=54765 를 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "25f56d88-750b-4acc-a9b5-4a070497f9ba",
      "metadata": {
        "id": "25f56d88-750b-4acc-a9b5-4a070497f9ba"
      },
      "outputs": [],
      "source": [
        "tfds.image_classification.cats_vs_dogs._URL = \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "aff3fc02",
      "metadata": {
        "id": "aff3fc02"
      },
      "outputs": [],
      "source": [
        "data = tfds.load('cats_vs_dogs', split='train', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "84be5a6d",
      "metadata": {
        "tags": [],
        "id": "84be5a6d"
      },
      "outputs": [],
      "source": [
        "data = tfds.load('cats_vs_dogs', split='train[:10000]', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b87b9123",
      "metadata": {
        "id": "b87b9123"
      },
      "outputs": [],
      "source": [
        "data = tfds.load('cats_vs_dogs', split='train[:20%]', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "28f5bb67",
      "metadata": {
        "id": "28f5bb67"
      },
      "outputs": [],
      "source": [
        "data = tfds.load('cats_vs_dogs', split='train[-1000:]+train[:1000]', \n",
        "                 as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b11136c6",
      "metadata": {
        "id": "b11136c6"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('cats_vs_dogs', split='train[:80%]', \n",
        "                       as_supervised=True)\n",
        "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', \n",
        "                            as_supervised=True)\n",
        "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]',\n",
        "                       as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bea8477c",
      "metadata": {
        "scrolled": true,
        "id": "bea8477c",
        "outputId": "9234f915-3e4e-4124-b399-d2ce69232034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18610\n"
          ]
        }
      ],
      "source": [
        "train_length = [i for i,_ in enumerate(train_data)][-1] + 1\n",
        "print(train_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d59998ce",
      "metadata": {
        "id": "d59998ce",
        "outputId": "53767df8-5f6c-492a-97b7-9f06adda4a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18610"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tf.data.experimental.cardinality(train_data).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d91db041",
      "metadata": {
        "id": "d91db041",
        "outputId": "54b6fbdf-9143-4d1a-eb47-a72ec9f9f8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 10000\n"
          ]
        }
      ],
      "source": [
        "train_data, info = tfds.load('fashion_mnist', with_info=True)\n",
        "print(info.splits['train'].num_examples, info.splits['test'].num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37f869e",
      "metadata": {
        "id": "e37f869e"
      },
      "source": [
        "## TFRecord 이해하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "766f4588",
      "metadata": {
        "id": "766f4588",
        "outputId": "c83a31ba-6143-44ff-aa5f-393c1c4e6d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.1,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data, info = tfds.load(\"mnist\", with_info=True)\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6024b18e",
      "metadata": {
        "scrolled": true,
        "id": "6024b18e",
        "outputId": "0783add3-9d9c-4ea7-dc8b-710f73a3c35b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Tensor: shape=(), dtype=string, numpy=b\"\\n\\x85\\x03\\n\\xf2\\x02\\n\\x05image\\x12\\xe8\\x02\\n\\xe5\\x02\\n\\xe2\\x02\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01)IDAT(\\x91\\xc5\\xd2\\xbdK\\xc3P\\x14\\x05\\xf0S(v\\x13)\\x04,.\\x82\\xc5Aq\\xac\\xedb\\x1d\\xdc\\n.\\x12\\x87n\\x0e\\x82\\x93\\x7f@Q\\xb2\\x08\\xba\\tbQ0.\\xe2\\xe2\\xd4\\xb1\\xa2h\\x9c\\x82\\xba\\x8a(\\nq\\xf0\\x83Fh\\x95\\n6\\x88\\xe7R\\x87\\x88\\xf9\\xa8Y\\xf5\\x0e\\x8f\\xc7\\xfd\\xdd\\x0b\\x87\\xc7\\x03\\xfe\\xbeb\\x9d\\xadT\\x927Q\\xe3\\xe9\\x07:\\xab\\xbf\\xf4\\xf3\\xcf\\xf6\\x8a\\xd9\\x14\\xd29\\xea\\xb0\\x1eKH\\xde\\xab\\xea%\\xaba\\x1b=\\xa4P/\\xf5\\x02\\xd7\\\\\\x07\\x00\\xc4=,L\\xc0,>\\x01@2\\xf6\\x12\\xde\\x9c\\xde[t/\\xb3\\x0e\\x87\\xa2\\xe2\\xc2\\xe0A<\\xca\\xb26\\xd5(\\x1b\\xa9\\xd3\\xe8\\x0e\\xf5\\x86\\x17\\xceE\\xdarV\\xae\\xb7_\\xf3AR\\r!I\\xf7(\\x06m\\xaaE\\xbb\\xb6\\xac\\r*\\x9b$e<\\xb8\\xd7\\xa2\\x0e\\x00\\xd0l\\x92\\xb2\\xd5\\x15\\xcc\\xae'\\x00\\xf4m\\x08O'+\\xc2y\\x9f\\x8d\\xc9\\x15\\x80\\xfe\\x99[q\\x962@CN|i\\xf7\\xa9!=\\xd7 \\xab\\x19\\x00\\xc8\\xd6\\xb8\\xeb\\xa1\\xf0\\xd8l\\xca\\xfb]\\xee\\xfb]*\\x9fV\\xe1\\x07\\xb7\\xc9\\x8b55\\xe7M\\xef\\xb0\\x04\\xc0\\xfd&\\x89\\x01<\\xbe\\xf9\\x03*\\x8a\\xf5\\x81\\x7f\\xaa/2y\\x87ks\\xec\\x1e\\xc1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x02\">\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "filename = os.path.join(os.path.expanduser('~') + \n",
        "                        '/tensorflow_datasets/mnist/3.0.1/mnist-test.tfrecord-00000-of-00001')\n",
        "raw_dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    print(repr(raw_record))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5e136603",
      "metadata": {
        "id": "5e136603",
        "outputId": "3fae18ab-a4dd-4c2a-e2f8-ba8f405a9f56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image': <tf.Tensor: shape=(), dtype=string, numpy=b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01)IDAT(\\x91\\xc5\\xd2\\xbdK\\xc3P\\x14\\x05\\xf0S(v\\x13)\\x04,.\\x82\\xc5Aq\\xac\\xedb\\x1d\\xdc\\n.\\x12\\x87n\\x0e\\x82\\x93\\x7f@Q\\xb2\\x08\\xba\\tbQ0.\\xe2\\xe2\\xd4\\xb1\\xa2h\\x9c\\x82\\xba\\x8a(\\nq\\xf0\\x83Fh\\x95\\n6\\x88\\xe7R\\x87\\x88\\xf9\\xa8Y\\xf5\\x0e\\x8f\\xc7\\xfd\\xdd\\x0b\\x87\\xc7\\x03\\xfe\\xbeb\\x9d\\xadT\\x927Q\\xe3\\xe9\\x07:\\xab\\xbf\\xf4\\xf3\\xcf\\xf6\\x8a\\xd9\\x14\\xd29\\xea\\xb0\\x1eKH\\xde\\xab\\xea%\\xaba\\x1b=\\xa4P/\\xf5\\x02\\xd7\\\\\\x07\\x00\\xc4=,L\\xc0,>\\x01@2\\xf6\\x12\\xde\\x9c\\xde[t/\\xb3\\x0e\\x87\\xa2\\xe2\\xc2\\xe0A<\\xca\\xb26\\xd5(\\x1b\\xa9\\xd3\\xe8\\x0e\\xf5\\x86\\x17\\xceE\\xdarV\\xae\\xb7_\\xf3AR\\r!I\\xf7(\\x06m\\xaaE\\xbb\\xb6\\xac\\r*\\x9b$e<\\xb8\\xd7\\xa2\\x0e\\x00\\xd0l\\x92\\xb2\\xd5\\x15\\xcc\\xae'\\x00\\xf4m\\x08O'+\\xc2y\\x9f\\x8d\\xc9\\x15\\x80\\xfe\\x99[q\\x962@CN|i\\xf7\\xa9!=\\xd7 \\xab\\x19\\x00\\xc8\\xd6\\xb8\\xeb\\xa1\\xf0\\xd8l\\xca\\xfb]\\xee\\xfb]*\\x9fV\\xe1\\x07\\xb7\\xc9\\x8b55\\xe7M\\xef\\xb0\\x04\\xc0\\xfd&\\x89\\x01<\\xbe\\xf9\\x03*\\x8a\\xf5\\x81\\x7f\\xaa/2y\\x87ks\\xec\\x1e\\xc1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\">, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n"
          ]
        }
      ],
      "source": [
        "# 특성 디스크립션을 만듭니다.\n",
        "feature_description = {\n",
        "    'image': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "    # 위에서 만든 딕셔너리로 입력을 파싱합니다.\n",
        "    return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "parsed_dataset = raw_dataset.map(_parse_function)\n",
        "for parsed_record in parsed_dataset.take(1):\n",
        "    print((parsed_record))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc32d9c",
      "metadata": {
        "id": "ddc32d9c"
      },
      "source": [
        "## 텐서플로에서 데이터 관리를 위한 ETL 프로세스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f5196472",
      "metadata": {
        "id": "f5196472",
        "outputId": "8c9741b1-ad4e-4c0e-b499-5576a67f870c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "33/33 [==============================] - 27s 758ms/step - loss: 0.5011 - accuracy: 0.7556 - val_loss: 294.0117 - val_accuracy: 0.6211\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 13s 369ms/step - loss: 0.1332 - accuracy: 0.9406 - val_loss: 569.8804 - val_accuracy: 0.4766\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 13s 362ms/step - loss: 0.0461 - accuracy: 0.9786 - val_loss: 498.3898 - val_accuracy: 0.4766\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 13s 375ms/step - loss: 0.0233 - accuracy: 0.9912 - val_loss: 563.0200 - val_accuracy: 0.6523\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 13s 370ms/step - loss: 0.1343 - accuracy: 0.9562 - val_loss: 161.0210 - val_accuracy: 0.6758\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 13s 364ms/step - loss: 0.0867 - accuracy: 0.9640 - val_loss: 767.5318 - val_accuracy: 0.5273\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 15s 411ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 637.2518 - val_accuracy: 0.6367\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 13s 370ms/step - loss: 0.1025 - accuracy: 0.9766 - val_loss: 420.9426 - val_accuracy: 0.4375\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 13s 366ms/step - loss: 0.3541 - accuracy: 0.8880 - val_loss: 153.9806 - val_accuracy: 0.6562\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 13s 370ms/step - loss: 0.0494 - accuracy: 0.9834 - val_loss: 623.0939 - val_accuracy: 0.6016\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# 모델 정의 시작 #\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
        "                           input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "# 모델 정의 끝 #\n",
        "\n",
        "# 추출 단계 시작 #\n",
        "data = tfds.load('horses_or_humans', split='train', \n",
        "                 as_supervised=True)\n",
        "val_data = tfds.load('horses_or_humans', split='test', \n",
        "                     as_supervised=True)\n",
        "# 추출 단계 끝 #\n",
        "\n",
        "# 변환 단계 시작 #\n",
        "def augmentimages(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image/255)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
        "    return image, label\n",
        "\n",
        "train = data.map(augmentimages)\n",
        "train_batches = train.shuffle(100).batch(32)\n",
        "validation_batches = val_data.batch(32)\n",
        "# 변환 단계 끝 #\n",
        "\n",
        "# 로드 단계 시작 #\n",
        "history = model.fit(train_batches, epochs=10, \n",
        "                    validation_data=validation_batches)\n",
        "# 로드 단계 끝 #"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e35d16",
      "metadata": {
        "id": "a1e35d16"
      },
      "source": [
        "### 훈련 속도 향상을 위한 ETL 병렬화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "45b0c465",
      "metadata": {
        "id": "45b0c465"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('cats_vs_dogs', split='train', with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f7b36946",
      "metadata": {
        "id": "f7b36946"
      },
      "outputs": [],
      "source": [
        "file_pattern = os.path.join(\n",
        "    os.path.expanduser('~') + \n",
        "    '/tensorflow_datasets/cats_vs_dogs/4.0.0/cats_vs_dogs-train.tfrecord*'\n",
        ")\n",
        "files = tf.data.Dataset.list_files(file_pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "97f5cda6",
      "metadata": {
        "id": "97f5cda6"
      },
      "outputs": [],
      "source": [
        "train_dataset = files.interleave(\n",
        "    tf.data.TFRecordDataset, \n",
        "    cycle_length=4,\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b7ba844b",
      "metadata": {
        "id": "b7ba844b"
      },
      "outputs": [],
      "source": [
        "def read_tfrecord(serialized_example):\n",
        "    feature_description={\n",
        "        \"image\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
        "        \"label\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(\n",
        "        serialized_example, feature_description\n",
        "    )\n",
        "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image / 255\n",
        "    image = tf.image.resize(image, (300,300))\n",
        "    return image, example['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "54cc5785",
      "metadata": {
        "id": "54cc5785",
        "outputId": "7223e266-99f7-42fe-c085-32a3f18ba337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "train_dataset = train_dataset.map(read_tfrecord, num_parallel_calls=cores)\n",
        "# train_dataset = train_dataset.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "69f317e6",
      "metadata": {
        "id": "69f317e6"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(1024).batch(16)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "640def46",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "640def46",
        "outputId": "8474c953-e304-4a68-f1e8-0f0d0872d39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1454/1454 [==============================] - 69s 46ms/step - loss: 0.6212 - accuracy: 0.6484\n",
            "Epoch 2/10\n",
            "1454/1454 [==============================] - 68s 45ms/step - loss: 0.4835 - accuracy: 0.7677\n",
            "Epoch 3/10\n",
            "1454/1454 [==============================] - 68s 46ms/step - loss: 0.4105 - accuracy: 0.8115\n",
            "Epoch 4/10\n",
            "1454/1454 [==============================] - 67s 45ms/step - loss: 0.3409 - accuracy: 0.8485\n",
            "Epoch 5/10\n",
            "1454/1454 [==============================] - 68s 46ms/step - loss: 0.2801 - accuracy: 0.8798\n",
            "Epoch 6/10\n",
            "1454/1454 [==============================] - 69s 46ms/step - loss: 0.2080 - accuracy: 0.9147\n",
            "Epoch 7/10\n",
            "1454/1454 [==============================] - 68s 46ms/step - loss: 0.1461 - accuracy: 0.9402\n",
            "Epoch 8/10\n",
            "1454/1454 [==============================] - 69s 46ms/step - loss: 0.1042 - accuracy: 0.9601\n",
            "Epoch 9/10\n",
            "1454/1454 [==============================] - 69s 46ms/step - loss: 0.0789 - accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "1454/1454 [==============================] - 68s 45ms/step - loss: 0.0657 - accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f471ac70290>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model.fit(train_dataset, epochs=10, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "04-tfds.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}