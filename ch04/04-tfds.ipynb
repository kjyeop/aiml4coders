{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3105de88",
   "metadata": {},
   "source": [
    "# 4장. 텐서플로 데이터셋으로 공개 데이터 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e8541",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/aiml4coders/blob/main/ch04/04-tfds.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"61\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/aiml4coders/blob/main/ch04/04-tfds.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5f7ba",
   "metadata": {},
   "source": [
    "## TFDS 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bee79a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:44.864932Z",
     "iopub.status.busy": "2022-03-01T04:33:44.864404Z",
     "iopub.status.idle": "2022-03-01T04:33:49.763810Z",
     "shell.execute_reply": "2022-03-01T04:33:49.762937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 04:33:49.676380: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "mnist_data = tfds.load(\"fashion_mnist\")\n",
    "for item in mnist_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a439642d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:49.767893Z",
     "iopub.status.busy": "2022-03-01T04:33:49.767400Z",
     "iopub.status.idle": "2022-03-01T04:33:49.805555Z",
     "shell.execute_reply": "2022-03-01T04:33:49.804451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "mnist_train = tfds.load(name=\"fashion_mnist\", split=\"train\")\n",
    "assert isinstance(mnist_train, tf.data.Dataset)\n",
    "print(type(mnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d04694b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:49.809681Z",
     "iopub.status.busy": "2022-03-01T04:33:49.809458Z",
     "iopub.status.idle": "2022-03-01T04:33:49.875888Z",
     "shell.execute_reply": "2022-03-01T04:33:49.874887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['image', 'label'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 04:33:49.868456: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for item in mnist_train.take(1):\n",
    "    print(type(item))\n",
    "    print(item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1594fc0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:49.879376Z",
     "iopub.status.busy": "2022-03-01T04:33:49.879148Z",
     "iopub.status.idle": "2022-03-01T04:33:49.977701Z",
     "shell.execute_reply": "2022-03-01T04:33:49.976128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['image', 'label'])\n",
      "tf.Tensor(\n",
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 77]\n",
      "  [227]\n",
      "  [227]\n",
      "  [208]\n",
      "  [210]\n",
      "  [225]\n",
      "  [216]\n",
      "  [ 85]\n",
      "  [ 32]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 61]\n",
      "  [100]\n",
      "  [ 97]\n",
      "  [ 80]\n",
      "  [ 57]\n",
      "  [117]\n",
      "  [227]\n",
      "  [238]\n",
      "  [115]\n",
      "  [ 49]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [105]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 64]\n",
      "  [ 44]\n",
      "  [ 21]\n",
      "  [ 13]\n",
      "  [ 44]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [114]\n",
      "  [ 80]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 68]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 83]\n",
      "  [ 77]\n",
      "  [108]\n",
      "  [ 34]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 69]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 71]\n",
      "  [ 71]\n",
      "  [ 77]\n",
      "  [ 69]\n",
      "  [ 66]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 94]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 63]\n",
      "  [ 95]\n",
      "  [ 66]\n",
      "  [ 68]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 77]\n",
      "  [106]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [108]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 69]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [128]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 88]\n",
      "  [120]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 83]\n",
      "  [ 83]\n",
      "  [ 66]\n",
      "  [111]\n",
      "  [123]\n",
      "  [ 78]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 85]\n",
      "  [134]\n",
      "  [ 74]\n",
      "  [ 85]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 81]\n",
      "  [ 75]\n",
      "  [ 61]\n",
      "  [151]\n",
      "  [115]\n",
      "  [ 91]\n",
      "  [ 12]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 85]\n",
      "  [153]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 68]\n",
      "  [ 61]\n",
      "  [162]\n",
      "  [122]\n",
      "  [ 78]\n",
      "  [  6]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [ 75]\n",
      "  [154]\n",
      "  [ 85]\n",
      "  [ 80]\n",
      "  [ 71]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 49]\n",
      "  [191]\n",
      "  [132]\n",
      "  [ 72]\n",
      "  [ 15]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 58]\n",
      "  [ 66]\n",
      "  [174]\n",
      "  [115]\n",
      "  [ 66]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 78]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 66]\n",
      "  [ 49]\n",
      "  [222]\n",
      "  [131]\n",
      "  [ 77]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 69]\n",
      "  [ 55]\n",
      "  [179]\n",
      "  [139]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 80]\n",
      "  [ 64]\n",
      "  [ 55]\n",
      "  [242]\n",
      "  [111]\n",
      "  [ 95]\n",
      "  [ 44]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 57]\n",
      "  [159]\n",
      "  [180]\n",
      "  [ 55]\n",
      "  [ 92]\n",
      "  [ 64]\n",
      "  [ 72]\n",
      "  [ 74]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 78]\n",
      "  [ 55]\n",
      "  [ 66]\n",
      "  [255]\n",
      "  [ 97]\n",
      "  [108]\n",
      "  [ 49]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 74]\n",
      "  [ 66]\n",
      "  [145]\n",
      "  [153]\n",
      "  [ 72]\n",
      "  [ 83]\n",
      "  [ 58]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 80]\n",
      "  [ 30]\n",
      "  [132]\n",
      "  [255]\n",
      "  [ 37]\n",
      "  [122]\n",
      "  [ 60]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [ 69]\n",
      "  [142]\n",
      "  [180]\n",
      "  [142]\n",
      "  [ 57]\n",
      "  [ 64]\n",
      "  [ 78]\n",
      "  [ 74]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 85]\n",
      "  [ 21]\n",
      "  [185]\n",
      "  [227]\n",
      "  [ 37]\n",
      "  [143]\n",
      "  [ 63]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 71]\n",
      "  [136]\n",
      "  [194]\n",
      "  [126]\n",
      "  [ 46]\n",
      "  [ 69]\n",
      "  [ 75]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 78]\n",
      "  [ 38]\n",
      "  [139]\n",
      "  [185]\n",
      "  [ 60]\n",
      "  [151]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [145]\n",
      "  [177]\n",
      "  [ 78]\n",
      "  [ 49]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 72]\n",
      "  [ 63]\n",
      "  [ 80]\n",
      "  [156]\n",
      "  [117]\n",
      "  [153]\n",
      "  [ 55]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 10]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [157]\n",
      "  [163]\n",
      "  [ 61]\n",
      "  [ 55]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 60]\n",
      "  [ 98]\n",
      "  [156]\n",
      "  [132]\n",
      "  [ 58]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 13]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [157]\n",
      "  [143]\n",
      "  [ 43]\n",
      "  [ 61]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 71]\n",
      "  [ 58]\n",
      "  [ 80]\n",
      "  [157]\n",
      "  [120]\n",
      "  [ 66]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 81]\n",
      "  [ 74]\n",
      "  [156]\n",
      "  [114]\n",
      "  [ 35]\n",
      "  [ 72]\n",
      "  [ 71]\n",
      "  [ 75]\n",
      "  [ 78]\n",
      "  [ 72]\n",
      "  [ 66]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 63]\n",
      "  [165]\n",
      "  [119]\n",
      "  [ 68]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 23]\n",
      "  [ 85]\n",
      "  [ 81]\n",
      "  [177]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 77]\n",
      "  [ 71]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 72]\n",
      "  [ 75]\n",
      "  [ 74]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 75]\n",
      "  [ 64]\n",
      "  [ 37]\n",
      "  [173]\n",
      "  [ 95]\n",
      "  [ 72]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [ 81]\n",
      "  [ 86]\n",
      "  [160]\n",
      "  [ 20]\n",
      "  [ 75]\n",
      "  [ 77]\n",
      "  [ 77]\n",
      "  [ 80]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 89]\n",
      "  [ 78]\n",
      "  [ 81]\n",
      "  [ 83]\n",
      "  [ 80]\n",
      "  [ 74]\n",
      "  [ 20]\n",
      "  [177]\n",
      "  [ 77]\n",
      "  [ 74]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 49]\n",
      "  [ 77]\n",
      "  [ 91]\n",
      "  [200]\n",
      "  [  0]\n",
      "  [ 83]\n",
      "  [ 95]\n",
      "  [ 86]\n",
      "  [ 88]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 89]\n",
      "  [ 88]\n",
      "  [ 83]\n",
      "  [ 89]\n",
      "  [ 86]\n",
      "  [  0]\n",
      "  [191]\n",
      "  [ 78]\n",
      "  [ 80]\n",
      "  [ 24]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [ 71]\n",
      "  [108]\n",
      "  [165]\n",
      "  [  0]\n",
      "  [ 24]\n",
      "  [ 57]\n",
      "  [ 52]\n",
      "  [ 57]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 60]\n",
      "  [ 63]\n",
      "  [ 63]\n",
      "  [ 77]\n",
      "  [ 89]\n",
      "  [ 52]\n",
      "  [  0]\n",
      "  [211]\n",
      "  [ 97]\n",
      "  [ 77]\n",
      "  [ 61]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 68]\n",
      "  [ 91]\n",
      "  [117]\n",
      "  [137]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [216]\n",
      "  [ 94]\n",
      "  [ 97]\n",
      "  [ 57]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [115]\n",
      "  [105]\n",
      "  [185]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  1]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [153]\n",
      "  [ 78]\n",
      "  [106]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [ 61]\n",
      "  [ 41]\n",
      "  [103]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [ 47]\n",
      "  [ 69]\n",
      "  [ 23]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]], shape=(28, 28, 1), dtype=uint8)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 04:33:49.932028: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for item in mnist_train.take(1):\n",
    "    print(type(item))\n",
    "    print(item.keys())\n",
    "    print(item['image'])\n",
    "    print(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeac7308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:49.981513Z",
     "iopub.status.busy": "2022-03-01T04:33:49.981283Z",
     "iopub.status.idle": "2022-03-01T04:33:50.044225Z",
     "shell.execute_reply": "2022-03-01T04:33:50.042994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='fashion_mnist',\n",
      "    full_name='fashion_mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
      "    data_path='/home/haesun/tensorflow_datasets/fashion_mnist/3.0.1',\n",
      "    download_size=29.45 MiB,\n",
      "    dataset_size=36.42 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
      "      author    = {Han Xiao and\n",
      "                   Kashif Rasul and\n",
      "                   Roland Vollgraf},\n",
      "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
      "                   Algorithms},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1708.07747},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1708.07747},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1708.07747},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist_test, info = tfds.load(name=\"fashion_mnist\", with_info=\"true\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9013edc",
   "metadata": {},
   "source": [
    "## 케라스 모델에서 TFDS 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202cc8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:50.048337Z",
     "iopub.status.busy": "2022-03-01T04:33:50.048089Z",
     "iopub.status.idle": "2022-03-01T04:33:50.556206Z",
     "shell.execute_reply": "2022-03-01T04:33:50.555443Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = \\\n",
    "    mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c4b935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:50.560486Z",
     "iopub.status.busy": "2022-03-01T04:33:50.559948Z",
     "iopub.status.idle": "2022-03-01T04:33:52.857251Z",
     "shell.execute_reply": "2022-03-01T04:33:52.856640Z"
    }
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = \\\n",
    "    tfds.as_numpy(tfds.load('fashion_mnist',\n",
    "                            split = ['train', 'test'], \n",
    "                            batch_size=-1, \n",
    "                            as_supervised=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d90467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:33:52.861864Z",
     "iopub.status.busy": "2022-03-01T04:33:52.861130Z",
     "iopub.status.idle": "2022-03-01T04:34:11.065344Z",
     "shell.execute_reply": "2022-03-01T04:34:11.064344Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5259 - accuracy: 0.8130\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3997 - accuracy: 0.8540\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3686 - accuracy: 0.8656\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8731\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3286 - accuracy: 0.8777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b1c63dd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = \\\n",
    "    tfds.load('fashion_mnist', \n",
    "              split = ['train', 'test'],\n",
    "              batch_size=-1, \n",
    "              as_supervised=True)\n",
    "\n",
    "training_images = tf.cast(training_images, tf.float32) / 255.0\n",
    "test_images = tf.cast(test_images, tf.float32) / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8731883e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:34:11.069863Z",
     "iopub.status.busy": "2022-03-01T04:34:11.069214Z",
     "iopub.status.idle": "2022-03-01T04:39:38.610260Z",
     "shell.execute_reply": "2022-03-01T04:39:38.609430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/103 [==============================] - 31s 292ms/step - loss: 2.9181 - accuracy: 0.8053\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 29s 279ms/step - loss: 0.1262 - accuracy: 0.9562\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 30s 295ms/step - loss: 0.1090 - accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 29s 279ms/step - loss: 0.1605 - accuracy: 0.9572\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 29s 280ms/step - loss: 0.0869 - accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 29s 279ms/step - loss: 0.0496 - accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 29s 282ms/step - loss: 0.0116 - accuracy: 0.9951\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 29s 282ms/step - loss: 6.7040e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 29s 281ms/step - loss: 1.7499e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 29s 281ms/step - loss: 6.7044e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b14519390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True) \n",
    "\n",
    "train_batches = data.shuffle(100).batch(10)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batches, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11dd9128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:39:38.613959Z",
     "iopub.status.busy": "2022-03-01T04:39:38.613733Z",
     "iopub.status.idle": "2022-03-01T04:39:38.654593Z",
     "shell.execute_reply": "2022-03-01T04:39:38.653760Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df701a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:39:38.658603Z",
     "iopub.status.busy": "2022-03-01T04:39:38.658388Z",
     "iopub.status.idle": "2022-03-01T04:39:38.662568Z",
     "shell.execute_reply": "2022-03-01T04:39:38.661735Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_batches = val_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f5abb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:39:38.666107Z",
     "iopub.status.busy": "2022-03-01T04:39:38.665885Z",
     "iopub.status.idle": "2022-03-01T04:45:06.976629Z",
     "shell.execute_reply": "2022-03-01T04:45:06.975816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/103 [==============================] - 31s 300ms/step - loss: 5.0541e-05 - accuracy: 1.0000 - val_loss: 3.1031 - val_accuracy: 0.8633\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 30s 295ms/step - loss: 4.0494e-05 - accuracy: 1.0000 - val_loss: 3.1764 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 30s 295ms/step - loss: 3.3339e-05 - accuracy: 1.0000 - val_loss: 3.2435 - val_accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 30s 296ms/step - loss: 2.8903e-05 - accuracy: 1.0000 - val_loss: 3.3048 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 30s 294ms/step - loss: 2.4731e-05 - accuracy: 1.0000 - val_loss: 3.3506 - val_accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 31s 299ms/step - loss: 2.1547e-05 - accuracy: 1.0000 - val_loss: 3.4111 - val_accuracy: 0.8555\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 31s 299ms/step - loss: 1.8975e-05 - accuracy: 1.0000 - val_loss: 3.4599 - val_accuracy: 0.8555\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 33s 315ms/step - loss: 1.6828e-05 - accuracy: 1.0000 - val_loss: 3.5026 - val_accuracy: 0.8555\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 30s 295ms/step - loss: 1.4828e-05 - accuracy: 1.0000 - val_loss: 3.5545 - val_accuracy: 0.8555\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 30s 294ms/step - loss: 1.3471e-05 - accuracy: 1.0000 - val_loss: 3.5980 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b1c592ba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches, epochs=10,\n",
    "          validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4241e",
   "metadata": {},
   "source": [
    "### 특정 버전의 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e825b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:06.980995Z",
     "iopub.status.busy": "2022-03-01T04:45:06.980319Z",
     "iopub.status.idle": "2022-03-01T04:45:07.045794Z",
     "shell.execute_reply": "2022-03-01T04:45:07.044886Z"
    }
   },
   "outputs": [],
   "source": [
    "data, info = tfds.load(\"horses_or_humans:3.0.0\", with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad1df2",
   "metadata": {},
   "source": [
    "## 데이터 증식을 위해 매핑 함수 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec01220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:07.050666Z",
     "iopub.status.busy": "2022-03-01T04:45:07.050424Z",
     "iopub.status.idle": "2022-03-01T04:45:07.093757Z",
     "shell.execute_reply": "2022-03-01T04:45:07.092881Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "train_batches = data.shuffle(100).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd15b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:07.098057Z",
     "iopub.status.busy": "2022-03-01T04:45:07.097815Z",
     "iopub.status.idle": "2022-03-01T04:45:07.101873Z",
     "shell.execute_reply": "2022-03-01T04:45:07.101102Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7908101b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:07.105433Z",
     "iopub.status.busy": "2022-03-01T04:45:07.105223Z",
     "iopub.status.idle": "2022-03-01T04:45:07.164254Z",
     "shell.execute_reply": "2022-03-01T04:45:07.163180Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data.map(augmentimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f922f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:07.168496Z",
     "iopub.status.busy": "2022-03-01T04:45:07.168155Z",
     "iopub.status.idle": "2022-03-01T04:45:07.173214Z",
     "shell.execute_reply": "2022-03-01T04:45:07.172519Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a8f4b",
   "metadata": {},
   "source": [
    "### 텐서플로 애드온 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a255512e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:07.176882Z",
     "iopub.status.busy": "2022-03-01T04:45:07.176298Z",
     "iopub.status.idle": "2022-03-01T04:45:08.928862Z",
     "shell.execute_reply": "2022-03-01T04:45:08.928025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /mnt/disks/sdb/github/aiml4coders/.env/lib/python3.7/site-packages (0.16.1)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /mnt/disks/sdb/github/aiml4coders/.env/lib/python3.7/site-packages (from tensorflow-addons) (2.13.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc21f73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:08.933046Z",
     "iopub.status.busy": "2022-03-01T04:45:08.932751Z",
     "iopub.status.idle": "2022-03-01T04:45:09.001510Z",
     "shell.execute_reply": "2022-03-01T04:45:09.000604Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1af629",
   "metadata": {},
   "source": [
    "## 사용자 정의 분할 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aff3fc02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.006109Z",
     "iopub.status.busy": "2022-03-01T04:45:09.005570Z",
     "iopub.status.idle": "2022-03-01T04:45:09.051414Z",
     "shell.execute_reply": "2022-03-01T04:45:09.050571Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tfds.load('cats_vs_dogs', split='train', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84be5a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.055651Z",
     "iopub.status.busy": "2022-03-01T04:45:09.055085Z",
     "iopub.status.idle": "2022-03-01T04:45:09.097147Z",
     "shell.execute_reply": "2022-03-01T04:45:09.096479Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tfds.load('cats_vs_dogs', split='train[:10000]', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b87b9123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.101207Z",
     "iopub.status.busy": "2022-03-01T04:45:09.100985Z",
     "iopub.status.idle": "2022-03-01T04:45:09.145475Z",
     "shell.execute_reply": "2022-03-01T04:45:09.144769Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tfds.load('cats_vs_dogs', split='train[:20%]', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28f5bb67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.150244Z",
     "iopub.status.busy": "2022-03-01T04:45:09.149403Z",
     "iopub.status.idle": "2022-03-01T04:45:09.192128Z",
     "shell.execute_reply": "2022-03-01T04:45:09.191400Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tfds.load('cats_vs_dogs', split='train[-1000:]+train[:1000]', \n",
    "                 as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11136c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.197054Z",
     "iopub.status.busy": "2022-03-01T04:45:09.196377Z",
     "iopub.status.idle": "2022-03-01T04:45:09.308559Z",
     "shell.execute_reply": "2022-03-01T04:45:09.308020Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tfds.load('cats_vs_dogs', split='train[:80%]', \n",
    "                       as_supervised=True)\n",
    "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', \n",
    "                            as_supervised=True)\n",
    "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]',\n",
    "                       as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bea8477c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:09.312985Z",
     "iopub.status.busy": "2022-03-01T04:45:09.312316Z",
     "iopub.status.idle": "2022-03-01T04:45:13.968484Z",
     "shell.execute_reply": "2022-03-01T04:45:13.967649Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "train_length = [i for i,_ in enumerate(train_data)][-1] + 1\n",
    "print(train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59998ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:13.971966Z",
     "iopub.status.busy": "2022-03-01T04:45:13.971752Z",
     "iopub.status.idle": "2022-03-01T04:45:13.978389Z",
     "shell.execute_reply": "2022-03-01T04:45:13.977788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18610"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(train_data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d91db041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:13.981914Z",
     "iopub.status.busy": "2022-03-01T04:45:13.981426Z",
     "iopub.status.idle": "2022-03-01T04:45:14.040741Z",
     "shell.execute_reply": "2022-03-01T04:45:14.040146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "train_data, info = tfds.load('fashion_mnist', with_info=True)\n",
    "print(info.splits['train'].num_examples, info.splits['test'].num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f869e",
   "metadata": {},
   "source": [
    "## TFRecord 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "766f4588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:14.044676Z",
     "iopub.status.busy": "2022-03-01T04:45:14.044245Z",
     "iopub.status.idle": "2022-03-01T04:45:14.107203Z",
     "shell.execute_reply": "2022-03-01T04:45:14.106207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='/home/haesun/tensorflow_datasets/mnist/3.0.1',\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data, info = tfds.load(\"mnist\", with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6024b18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:14.111120Z",
     "iopub.status.busy": "2022-03-01T04:45:14.110674Z",
     "iopub.status.idle": "2022-03-01T04:45:14.131757Z",
     "shell.execute_reply": "2022-03-01T04:45:14.130839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b\"\\n\\x85\\x03\\n\\xf2\\x02\\n\\x05image\\x12\\xe8\\x02\\n\\xe5\\x02\\n\\xe2\\x02\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01)IDAT(\\x91\\xc5\\xd2\\xbdK\\xc3P\\x14\\x05\\xf0S(v\\x13)\\x04,.\\x82\\xc5Aq\\xac\\xedb\\x1d\\xdc\\n.\\x12\\x87n\\x0e\\x82\\x93\\x7f@Q\\xb2\\x08\\xba\\tbQ0.\\xe2\\xe2\\xd4\\xb1\\xa2h\\x9c\\x82\\xba\\x8a(\\nq\\xf0\\x83Fh\\x95\\n6\\x88\\xe7R\\x87\\x88\\xf9\\xa8Y\\xf5\\x0e\\x8f\\xc7\\xfd\\xdd\\x0b\\x87\\xc7\\x03\\xfe\\xbeb\\x9d\\xadT\\x927Q\\xe3\\xe9\\x07:\\xab\\xbf\\xf4\\xf3\\xcf\\xf6\\x8a\\xd9\\x14\\xd29\\xea\\xb0\\x1eKH\\xde\\xab\\xea%\\xaba\\x1b=\\xa4P/\\xf5\\x02\\xd7\\\\\\x07\\x00\\xc4=,L\\xc0,>\\x01@2\\xf6\\x12\\xde\\x9c\\xde[t/\\xb3\\x0e\\x87\\xa2\\xe2\\xc2\\xe0A<\\xca\\xb26\\xd5(\\x1b\\xa9\\xd3\\xe8\\x0e\\xf5\\x86\\x17\\xceE\\xdarV\\xae\\xb7_\\xf3AR\\r!I\\xf7(\\x06m\\xaaE\\xbb\\xb6\\xac\\r*\\x9b$e<\\xb8\\xd7\\xa2\\x0e\\x00\\xd0l\\x92\\xb2\\xd5\\x15\\xcc\\xae'\\x00\\xf4m\\x08O'+\\xc2y\\x9f\\x8d\\xc9\\x15\\x80\\xfe\\x99[q\\x962@CN|i\\xf7\\xa9!=\\xd7 \\xab\\x19\\x00\\xc8\\xd6\\xb8\\xeb\\xa1\\xf0\\xd8l\\xca\\xfb]\\xee\\xfb]*\\x9fV\\xe1\\x07\\xb7\\xc9\\x8b55\\xe7M\\xef\\xb0\\x04\\xc0\\xfd&\\x89\\x01<\\xbe\\xf9\\x03*\\x8a\\xf5\\x81\\x7f\\xaa/2y\\x87ks\\xec\\x1e\\xc1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\\n\\x0e\\n\\x05label\\x12\\x05\\x1a\\x03\\n\\x01\\x02\">\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "filename = os.path.join(os.path.expanduser('~') + \n",
    "                        '/tensorflow_datasets/mnist/3.0.1/mnist-test.tfrecord-00000-of-00001')\n",
    "raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e136603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:14.135618Z",
     "iopub.status.busy": "2022-03-01T04:45:14.135189Z",
     "iopub.status.idle": "2022-03-01T04:45:14.193296Z",
     "shell.execute_reply": "2022-03-01T04:45:14.192470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <tf.Tensor: shape=(), dtype=string, numpy=b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01)IDAT(\\x91\\xc5\\xd2\\xbdK\\xc3P\\x14\\x05\\xf0S(v\\x13)\\x04,.\\x82\\xc5Aq\\xac\\xedb\\x1d\\xdc\\n.\\x12\\x87n\\x0e\\x82\\x93\\x7f@Q\\xb2\\x08\\xba\\tbQ0.\\xe2\\xe2\\xd4\\xb1\\xa2h\\x9c\\x82\\xba\\x8a(\\nq\\xf0\\x83Fh\\x95\\n6\\x88\\xe7R\\x87\\x88\\xf9\\xa8Y\\xf5\\x0e\\x8f\\xc7\\xfd\\xdd\\x0b\\x87\\xc7\\x03\\xfe\\xbeb\\x9d\\xadT\\x927Q\\xe3\\xe9\\x07:\\xab\\xbf\\xf4\\xf3\\xcf\\xf6\\x8a\\xd9\\x14\\xd29\\xea\\xb0\\x1eKH\\xde\\xab\\xea%\\xaba\\x1b=\\xa4P/\\xf5\\x02\\xd7\\\\\\x07\\x00\\xc4=,L\\xc0,>\\x01@2\\xf6\\x12\\xde\\x9c\\xde[t/\\xb3\\x0e\\x87\\xa2\\xe2\\xc2\\xe0A<\\xca\\xb26\\xd5(\\x1b\\xa9\\xd3\\xe8\\x0e\\xf5\\x86\\x17\\xceE\\xdarV\\xae\\xb7_\\xf3AR\\r!I\\xf7(\\x06m\\xaaE\\xbb\\xb6\\xac\\r*\\x9b$e<\\xb8\\xd7\\xa2\\x0e\\x00\\xd0l\\x92\\xb2\\xd5\\x15\\xcc\\xae'\\x00\\xf4m\\x08O'+\\xc2y\\x9f\\x8d\\xc9\\x15\\x80\\xfe\\x99[q\\x962@CN|i\\xf7\\xa9!=\\xd7 \\xab\\x19\\x00\\xc8\\xd6\\xb8\\xeb\\xa1\\xf0\\xd8l\\xca\\xfb]\\xee\\xfb]*\\x9fV\\xe1\\x07\\xb7\\xc9\\x8b55\\xe7M\\xef\\xb0\\x04\\xc0\\xfd&\\x89\\x01<\\xbe\\xf9\\x03*\\x8a\\xf5\\x81\\x7f\\xaa/2y\\x87ks\\xec\\x1e\\xc1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\">, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n"
     ]
    }
   ],
   "source": [
    "# 특성 디스크립션을 만듭니다.\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # 위에서 만든 딕셔너리로 입력을 파싱합니다.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "for parsed_record in parsed_dataset.take(1):\n",
    "    print((parsed_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc32d9c",
   "metadata": {},
   "source": [
    "## 텐서플로에서 데이터 관리를 위한 ETL 프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5196472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:45:14.197076Z",
     "iopub.status.busy": "2022-03-01T04:45:14.196645Z",
     "iopub.status.idle": "2022-03-01T04:51:04.314663Z",
     "shell.execute_reply": "2022-03-01T04:51:04.313971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.4573 - accuracy: 0.7741 - val_loss: 416.3230 - val_accuracy: 0.4375\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.1263 - accuracy: 0.9533 - val_loss: 575.7719 - val_accuracy: 0.4141\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.1213 - accuracy: 0.9630 - val_loss: 636.6270 - val_accuracy: 0.4648\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 760.9930 - val_accuracy: 0.3750\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.1411 - accuracy: 0.9474 - val_loss: 297.4895 - val_accuracy: 0.3984\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 482.3256 - val_accuracy: 0.4375\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 418.0457 - val_accuracy: 0.4805\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 487.4778 - val_accuracy: 0.5234\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 643.3795 - val_accuracy: 0.4688\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 35s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 658.7106 - val_accuracy: 0.5234\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# 모델 정의 시작 #\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n",
    "                           input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "# 모델 정의 끝 #\n",
    "\n",
    "# 추출 단계 시작 #\n",
    "data = tfds.load('horses_or_humans', split='train', \n",
    "                 as_supervised=True)\n",
    "val_data = tfds.load('horses_or_humans', split='test', \n",
    "                     as_supervised=True)\n",
    "# 추출 단계 끝 #\n",
    "\n",
    "# 변환 단계 시작 #\n",
    "def augmentimages(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/255)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "    return image, label\n",
    "\n",
    "train = data.map(augmentimages)\n",
    "train_batches = train.shuffle(100).batch(32)\n",
    "validation_batches = val_data.batch(32)\n",
    "# 변환 단계 끝 #\n",
    "\n",
    "# 로드 단계 시작 #\n",
    "history = model.fit(train_batches, epochs=10, \n",
    "                    validation_data=validation_batches)\n",
    "# 로드 단계 끝 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e35d16",
   "metadata": {},
   "source": [
    "### 훈련 속도 향상을 위한 ETL 병렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45b0c465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.320927Z",
     "iopub.status.busy": "2022-03-01T04:51:04.317906Z",
     "iopub.status.idle": "2022-03-01T04:51:04.357003Z",
     "shell.execute_reply": "2022-03-01T04:51:04.356413Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tfds.load('cats_vs_dogs', split='train', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7b36946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.360840Z",
     "iopub.status.busy": "2022-03-01T04:51:04.360200Z",
     "iopub.status.idle": "2022-03-01T04:51:04.367605Z",
     "shell.execute_reply": "2022-03-01T04:51:04.367129Z"
    }
   },
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(\n",
    "    os.path.expanduser('~') + \n",
    "    '/tensorflow_datasets/cats_vs_dogs/4.0.0/cats_vs_dogs-train.tfrecord*'\n",
    ")\n",
    "files = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97f5cda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.370807Z",
     "iopub.status.busy": "2022-03-01T04:51:04.370388Z",
     "iopub.status.idle": "2022-03-01T04:51:04.385698Z",
     "shell.execute_reply": "2022-03-01T04:51:04.385071Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = files.interleave(\n",
    "    tf.data.TFRecordDataset, \n",
    "    cycle_length=4,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7ba844b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.389269Z",
     "iopub.status.busy": "2022-03-01T04:51:04.389068Z",
     "iopub.status.idle": "2022-03-01T04:51:04.394941Z",
     "shell.execute_reply": "2022-03-01T04:51:04.394070Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description={\n",
    "        \"image\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "        \"label\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(\n",
    "        serialized_example, feature_description\n",
    "    )\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255\n",
    "    image = tf.image.resize(image, (300,300))\n",
    "    return image, example['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54cc5785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.398344Z",
     "iopub.status.busy": "2022-03-01T04:51:04.398126Z",
     "iopub.status.idle": "2022-03-01T04:51:04.480648Z",
     "shell.execute_reply": "2022-03-01T04:51:04.479978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)\n",
    "train_dataset = train_dataset.map(read_tfrecord, num_parallel_calls=cores)\n",
    "train_dataset = train_dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69f317e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.484148Z",
     "iopub.status.busy": "2022-03-01T04:51:04.483507Z",
     "iopub.status.idle": "2022-03-01T04:51:04.488504Z",
     "shell.execute_reply": "2022-03-01T04:51:04.487897Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "640def46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T04:51:04.492040Z",
     "iopub.status.busy": "2022-03-01T04:51:04.491493Z",
     "iopub.status.idle": "2022-03-01T06:33:42.826278Z",
     "shell.execute_reply": "2022-03-01T06:33:42.825203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "     80/Unknown - 66s 812ms/step - loss: 0.7724 - accuracy: 0.5066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    103/Unknown - 84s 810ms/step - loss: 0.7546 - accuracy: 0.5049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    289/Unknown - 236s 812ms/step - loss: 0.7149 - accuracy: 0.5138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    297/Unknown - 242s 812ms/step - loss: 0.7144 - accuracy: 0.5130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    460/Unknown - 374s 811ms/step - loss: 0.7040 - accuracy: 0.5258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    488/Unknown - 397s 811ms/step - loss: 0.7029 - accuracy: 0.5260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    513/Unknown - 417s 811ms/step - loss: 0.7015 - accuracy: 0.5294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    515/Unknown - 418s 811ms/step - loss: 0.7015 - accuracy: 0.5295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    521/Unknown - 423s 811ms/step - loss: 0.7013 - accuracy: 0.5296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    602/Unknown - 489s 811ms/step - loss: 0.6984 - accuracy: 0.5349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    668/Unknown - 543s 811ms/step - loss: 0.6948 - accuracy: 0.5418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    686/Unknown - 557s 811ms/step - loss: 0.6943 - accuracy: 0.5426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    691/Unknown - 562s 812ms/step - loss: 0.6941 - accuracy: 0.5430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 593s 814ms/step - loss: 0.6913 - accuracy: 0.5478\n",
      "Epoch 2/10\n",
      "727/727 [==============================] - 609s 837ms/step - loss: 0.5845 - accuracy: 0.6909\n",
      "Epoch 3/10\n",
      "727/727 [==============================] - 613s 844ms/step - loss: 0.4792 - accuracy: 0.7664\n",
      "Epoch 4/10\n",
      "727/727 [==============================] - 621s 855ms/step - loss: 0.4029 - accuracy: 0.8169\n",
      "Epoch 5/10\n",
      "727/727 [==============================] - 618s 851ms/step - loss: 0.3381 - accuracy: 0.8492\n",
      "Epoch 6/10\n",
      "727/727 [==============================] - 618s 850ms/step - loss: 0.2671 - accuracy: 0.8881\n",
      "Epoch 7/10\n",
      "727/727 [==============================] - 625s 859ms/step - loss: 0.1962 - accuracy: 0.9183\n",
      "Epoch 8/10\n",
      "727/727 [==============================] - 618s 850ms/step - loss: 0.1382 - accuracy: 0.9451\n",
      "Epoch 9/10\n",
      "727/727 [==============================] - 618s 850ms/step - loss: 0.0850 - accuracy: 0.9661\n",
      "Epoch 10/10\n",
      "727/727 [==============================] - 621s 854ms/step - loss: 0.0772 - accuracy: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b646c92b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
