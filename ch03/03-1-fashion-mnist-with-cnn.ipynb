{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e62de7a",
   "metadata": {},
   "source": [
    "# 3장. 기초를 넘어서: 이미지에서 특징 감지하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a991c",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/aiml4coders/blob/main/ch03/03-1-fashion-mnist-with-cnn.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"61\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/aiml4coders/blob/main/ch03/03-1-fashion-mnist-with-cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d530c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8b58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0485fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1447f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 22:34:49.133972: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                             input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52989705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a703be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.4415 - accuracy: 0.8398\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2979 - accuracy: 0.8905\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.2501 - accuracy: 0.9078\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.2146 - accuracy: 0.9198\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1910 - accuracy: 0.9290\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.1676 - accuracy: 0.9358\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1448 - accuracy: 0.9449\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.1289 - accuracy: 0.9510\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.1121 - accuracy: 0.9573\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0998 - accuracy: 0.9625\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0870 - accuracy: 0.9665\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0787 - accuracy: 0.9703\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0695 - accuracy: 0.9732\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0608 - accuracy: 0.9767\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0538 - accuracy: 0.9789\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0504 - accuracy: 0.9805\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0453 - accuracy: 0.9830\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0416 - accuracy: 0.9847\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0385 - accuracy: 0.9855\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0347 - accuracy: 0.9872\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0360 - accuracy: 0.9865\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0330 - accuracy: 0.9881\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0338 - accuracy: 0.9878\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0267 - accuracy: 0.9897\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0271 - accuracy: 0.9900\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0269 - accuracy: 0.9904\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0264 - accuracy: 0.9909\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0250 - accuracy: 0.9913\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0221 - accuracy: 0.9919\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0211 - accuracy: 0.9931\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0244 - accuracy: 0.9916\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0209 - accuracy: 0.9927\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0184 - accuracy: 0.9936\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0191 - accuracy: 0.9933\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0195 - accuracy: 0.9939\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0169 - accuracy: 0.9946\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0171 - accuracy: 0.9943\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0178 - accuracy: 0.9946\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0191 - accuracy: 0.9943\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0203 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79f6160080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400b8a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9168 - accuracy: 0.9117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9167942404747009, 0.9117000102996826]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab72763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5326072e-29 4.8770887e-16 5.4415356e-30 2.2476692e-24 1.1890590e-34\n",
      " 1.2836127e-17 7.3720566e-21 4.9091139e-18 1.4365762e-15 1.0000000e+00]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e92d97",
   "metadata": {},
   "source": [
    "## 합성곱 신경망 살펴 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995ab17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743f460",
   "metadata": {},
   "source": [
    "## 말과 사람을 구별하는 CNN 만들기\n",
    "\n",
    "### 케라스 ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9948afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/\n",
    "                                            horse-or-human.zip\"\n",
    "file_name = \"horse-or-human.zip\"\n",
    "training_dir = 'horse-or-human/training/'\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "zip_ref.extractall(training_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 전체 이미지를 1./255로 스케일을 조정합니다.\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  training_dir,\n",
    "  target_size=(300, 300),\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812c47a",
   "metadata": {},
   "source": [
    "### 말-사람 데이터셋을 위한 CNN 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f573b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu' , \n",
    "              input_shape=(300, 300, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2293a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 149, 149, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83067f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd6a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
